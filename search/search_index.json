{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BlockIndex Documentation Welcome to the official documentation for BlockIndex. BlockIndex a highly flexible open source indexer that aims to work with all blockchains. Our core codebase is free and publicly available on GitHub. Getting Started If you're new to BlockIndex, you can start here. Installation Configuration Alert Deployment Developers","title":"Home"},{"location":"#blockindex-documentation","text":"Welcome to the official documentation for BlockIndex. BlockIndex a highly flexible open source indexer that aims to work with all blockchains. Our core codebase is free and publicly available on GitHub.","title":"BlockIndex Documentation"},{"location":"#getting-started","text":"If you're new to BlockIndex, you can start here. Installation Configuration Alert Deployment Developers","title":"Getting Started"},{"location":"alert/","text":"Alert AlertTask Each AlertTask has its own set of user-defined criteria and monitors the most recent blockchain update. If any transactions or events fit the requirements, the AlertTask will send a webhook to the previously specified target url. For example, one can listen to ERC20 transactions for a specific address, and if any of the ERC20 transactions has a dollar value greater than $1,000 USD, the AlertTask will send an alert. How to create an AlertTask An AlertTask can be created by sending a post request to api/v1/alert_tasks with the following parameters. name type description type enum At the moment, Blockindex only supports the Event type, which allows AlertTask to listen for Blockchain events. index_addr_id id the IndexAddr model's id field cls_name enum Currently, Blockindex provides two distinct cls: ERC20TransAlert and ERC721TransAlert . In the following section, we will go into greater detail. params dict different cls require different parameters to establish their criteria. You may find the schema for different cls' parameters in /schemas/alert_task_params.py . We will also go into more detail in the following section. target_url url the url to which the webhook will send the request. AlertTask Class ERC20TransAlert ERC20TranAlert is used to monitor ERC20 transactions. name type description symbols List[str] List of symbols the alert listens to. value_threshold Optional[int] The threshold for sending alert. dollar_value_threshold Optional[int] The threshold for sending alert. * Note. Either one of the thresholds (value thresdhold or dollar value thresdhold) is met, the alert will be dispatched. Python post example headers = {\"access_token\": \"blockindex\"} data = { \"type\": \"Event\", \"index_addr_id\": 6, \"cls_name\": \"ERC20TransAlert\", \"params\": { \"symbols\": [\"ETH\", \"USDC\", \"USDT\"], \"dollar_value_threshold\": 1e4, }, \"target_url\": \"http://localhost:8080\" } requests.post(\"http://localhost:8000/api/v1/alert_tasks\", json=data, headers=headers) The alert is a POST request with the payload, which is essentially the relevant event data, as shown below. {\"data\": {\"args\": { \"from\": \"0x80985910b333c8B0698e5FA7C43f77a40b3235c3\", \"to\": \"0x562680a4dC50ed2f14d75BF31f494cfE0b8D10a1\", \"value\": 114002361 }, \"event\": \"Transfer\", \"logIndex\": 51, \"transactionIndex\": 11, \"transactionHash\": \"0xde9cc1ec6e3d143ae16279e85555957a6aef5258291f6116cc5eb10207571633\", \"address\": \"0xdAC17F958D2ee523a2206206994597C13D831ec7\", \"blockHash\": \"0x7b01fa30affa04220d928f27475769520b17deaa72ea66f1961610cba12cc9ea\", \"blockNumber\": 16262893 } } ERC721TransAlert ERC721TranAlert is used to monitor ERC721 transactions. name type description names List[str] List of ERC721 name Python post example headers = {\"access_token\": \"blockindex\"} data = { \"type\": \"Event\", \"index_addr_id\": 1, \"cls_name\": \"ERC721TransAlert\", \"params\": { \"names\": [\"BoredApeYachtClub\"] }, \"target_url\": \"http://localhost:8080\" } requests.post(\"http://localhost:8000/api/v1/alert_tasks\", json=data, headers=headers) The alert is a POST request with the payload, which is essentially the relevant event data, as shown below. { 'args': { 'from': '0xDBfD76AF2157Dc15eE4e57F3f942bB45Ba84aF24', 'to': '0x66aB6D9362d4F35596279692F0251Db635165871', 'tokenId': 4645 }, 'event': 'Transfer', 'logIndex': 1, 'transactionIndex': 0, 'transactionHash': '0x09cddab1cb9014ce3974dc366b52732a5b25aa0d41971ff4ad0e6eea2f055e2e', 'address': '0xBC4CA0EdA7647A8aB7C2061c2E118A18a936f13D', 'blockHash': '0x69d7b8162d082779ebb2efc313b19a0c3d6fa6ccfce99bf876219679f3f968d3', 'blockNumber': 16267740 }","title":"Alert"},{"location":"alert/#alert","text":"","title":"Alert"},{"location":"alert/#alerttask","text":"Each AlertTask has its own set of user-defined criteria and monitors the most recent blockchain update. If any transactions or events fit the requirements, the AlertTask will send a webhook to the previously specified target url. For example, one can listen to ERC20 transactions for a specific address, and if any of the ERC20 transactions has a dollar value greater than $1,000 USD, the AlertTask will send an alert.","title":"AlertTask"},{"location":"alert/#how-to-create-an-alerttask","text":"An AlertTask can be created by sending a post request to api/v1/alert_tasks with the following parameters. name type description type enum At the moment, Blockindex only supports the Event type, which allows AlertTask to listen for Blockchain events. index_addr_id id the IndexAddr model's id field cls_name enum Currently, Blockindex provides two distinct cls: ERC20TransAlert and ERC721TransAlert . In the following section, we will go into greater detail. params dict different cls require different parameters to establish their criteria. You may find the schema for different cls' parameters in /schemas/alert_task_params.py . We will also go into more detail in the following section. target_url url the url to which the webhook will send the request.","title":"How to create an AlertTask"},{"location":"alert/#alerttask-class","text":"","title":"AlertTask Class"},{"location":"alert/#erc20transalert","text":"ERC20TranAlert is used to monitor ERC20 transactions. name type description symbols List[str] List of symbols the alert listens to. value_threshold Optional[int] The threshold for sending alert. dollar_value_threshold Optional[int] The threshold for sending alert. * Note. Either one of the thresholds (value thresdhold or dollar value thresdhold) is met, the alert will be dispatched.","title":"ERC20TransAlert"},{"location":"alert/#python-post-example","text":"headers = {\"access_token\": \"blockindex\"} data = { \"type\": \"Event\", \"index_addr_id\": 6, \"cls_name\": \"ERC20TransAlert\", \"params\": { \"symbols\": [\"ETH\", \"USDC\", \"USDT\"], \"dollar_value_threshold\": 1e4, }, \"target_url\": \"http://localhost:8080\" } requests.post(\"http://localhost:8000/api/v1/alert_tasks\", json=data, headers=headers)","title":"Python post example"},{"location":"alert/#the-alert-is-a-post-request-with-the-payload-which-is-essentially-the-relevant-event-data-as-shown-below","text":"{\"data\": {\"args\": { \"from\": \"0x80985910b333c8B0698e5FA7C43f77a40b3235c3\", \"to\": \"0x562680a4dC50ed2f14d75BF31f494cfE0b8D10a1\", \"value\": 114002361 }, \"event\": \"Transfer\", \"logIndex\": 51, \"transactionIndex\": 11, \"transactionHash\": \"0xde9cc1ec6e3d143ae16279e85555957a6aef5258291f6116cc5eb10207571633\", \"address\": \"0xdAC17F958D2ee523a2206206994597C13D831ec7\", \"blockHash\": \"0x7b01fa30affa04220d928f27475769520b17deaa72ea66f1961610cba12cc9ea\", \"blockNumber\": 16262893 } }","title":"The alert is a POST request with the payload, which is essentially the relevant event data, as shown below."},{"location":"alert/#erc721transalert","text":"ERC721TranAlert is used to monitor ERC721 transactions. name type description names List[str] List of ERC721 name","title":"ERC721TransAlert"},{"location":"alert/#python-post-example_1","text":"headers = {\"access_token\": \"blockindex\"} data = { \"type\": \"Event\", \"index_addr_id\": 1, \"cls_name\": \"ERC721TransAlert\", \"params\": { \"names\": [\"BoredApeYachtClub\"] }, \"target_url\": \"http://localhost:8080\" } requests.post(\"http://localhost:8000/api/v1/alert_tasks\", json=data, headers=headers)","title":"Python post example"},{"location":"alert/#the-alert-is-a-post-request-with-the-payload-which-is-essentially-the-relevant-event-data-as-shown-below_1","text":"{ 'args': { 'from': '0xDBfD76AF2157Dc15eE4e57F3f942bB45Ba84aF24', 'to': '0x66aB6D9362d4F35596279692F0251Db635165871', 'tokenId': 4645 }, 'event': 'Transfer', 'logIndex': 1, 'transactionIndex': 0, 'transactionHash': '0x09cddab1cb9014ce3974dc366b52732a5b25aa0d41971ff4ad0e6eea2f055e2e', 'address': '0xBC4CA0EdA7647A8aB7C2061c2E118A18a936f13D', 'blockHash': '0x69d7b8162d082779ebb2efc313b19a0c3d6fa6ccfce99bf876219679f3f968d3', 'blockNumber': 16267740 }","title":"The alert is a POST request with the payload, which is essentially the relevant event data, as shown below."},{"location":"config/","text":"Configuration Configuration is done via environment variables. The following variables are available: API_V1_STR - The API endpoint for v1 of the API. Defaults to /api/v1 . API_KEY - The API key to use for the API. This is required for all API endpoints. SQLALCHEMY_DATABASE_URI - The database URI to use. CELERY_BROKER_URL - The broker URL to use for Celery. CELERY_RESULT_BACKEND - The result backend to use for Celery. INDEX_ALL : If set to true , all transactions/events will be indexed. If set to false , only the address that are in the database will be indexed. COINMARKETCAP_API_KEY - The API key to use for CoinMarketCap. ALERT_RETRIAL_MAX_CNT - The maximum number of times to retry an alert. ETH_WS_URL - The websocket URL to use for Ethereum JSON-RPC. ETH_URL - The URL to use for Ethereum JSON-RPC. BSC_URL - The URL to use for Binance Smart Chain JSON-RPC.","title":"Configuration"},{"location":"config/#configuration","text":"Configuration is done via environment variables. The following variables are available: API_V1_STR - The API endpoint for v1 of the API. Defaults to /api/v1 . API_KEY - The API key to use for the API. This is required for all API endpoints. SQLALCHEMY_DATABASE_URI - The database URI to use. CELERY_BROKER_URL - The broker URL to use for Celery. CELERY_RESULT_BACKEND - The result backend to use for Celery. INDEX_ALL : If set to true , all transactions/events will be indexed. If set to false , only the address that are in the database will be indexed. COINMARKETCAP_API_KEY - The API key to use for CoinMarketCap. ALERT_RETRIAL_MAX_CNT - The maximum number of times to retry an alert. ETH_WS_URL - The websocket URL to use for Ethereum JSON-RPC. ETH_URL - The URL to use for Ethereum JSON-RPC. BSC_URL - The URL to use for Binance Smart Chain JSON-RPC.","title":"Configuration"},{"location":"deployment/","text":"Deployment For easy deployment, we use docker compose to deploy on a single machine. The diagram belows show the architecture: Environment Setup Before deployment, you need to prepare docker and PostgreSQL in your environment. Here's some useful reference Docker PostgreSQL Linux downloads (Ubuntu) Postgres.app Google Cloud SQL AWS RDS Deploy Setup Set the following environment variables in .env file: COINMARKETCAP_API_KEY : Your CoinMarketCap API key ETH_WS_URL : Websocket json-RPC URL for ethereum POSTGRES_HOST : Host for PostgreSQL POSTGRES_PORT : Port for PostgreSQL POSTGRES_USER : User for PostgreSQL POSTGRES_PASSWORD : Password for PostgreSQL CELERY_BROKER_URL (Optional): Celery broker URL CELERY_RESULT_BACKEND (Optional): Celery Result URL EXT_ENDPOINT : External domain name API_ENDPOINT : FQDN for blockindex API FE_ENDPOINT : FQDN for frontend STATIC_DIR : The host machine directory that contains static files. Example for .env file: COINMARKETCAP_API_KEY=\"YOUR_KEY_HERE\" PYTHONPATH=. ETH_WS_URL=\"ws://localhost:8454\" # PostgreSQL settings POSTGRES_HOST=host.docker.internal POSTGRES_PORT=5432 POSTGRES_DB=blockindex POSTGRES_USER=blockindex POSTGRES_PASSWORD=blockindex CELERY_BROKER_URL=redis://redis:6379/0 CELERY_RESULT_BACKEND=redis://redis:6379/0 # Traefik EXT_ENDPOINT=blockindex.example API_ENDPOINT=demo-api.blockindex.dev FE_ENDPOINT=demo.blockindex.dev #nginx STATIC_DIR=/root/frontend Finally, execute the following command in root directory: docker compose -f prod.yml up -d Then the service could be visit via the following URL: BlockIndex API: http://api.localhost , http://api.${EXT_ENDPOINT} , http://${API_ENDPOINT} Static Files: http://nginx.localhost , http://nginx.${EXT_ENDPOINT} , http://${FE_ENDPOINT} Traefik Dashboard: http://traefik.localhost , http://traefik.${END_POINT}","title":"Deployment"},{"location":"deployment/#deployment","text":"For easy deployment, we use docker compose to deploy on a single machine. The diagram belows show the architecture:","title":"Deployment"},{"location":"deployment/#environment-setup","text":"Before deployment, you need to prepare docker and PostgreSQL in your environment. Here's some useful reference Docker PostgreSQL Linux downloads (Ubuntu) Postgres.app Google Cloud SQL AWS RDS","title":"Environment Setup"},{"location":"deployment/#deploy-setup","text":"Set the following environment variables in .env file: COINMARKETCAP_API_KEY : Your CoinMarketCap API key ETH_WS_URL : Websocket json-RPC URL for ethereum POSTGRES_HOST : Host for PostgreSQL POSTGRES_PORT : Port for PostgreSQL POSTGRES_USER : User for PostgreSQL POSTGRES_PASSWORD : Password for PostgreSQL CELERY_BROKER_URL (Optional): Celery broker URL CELERY_RESULT_BACKEND (Optional): Celery Result URL EXT_ENDPOINT : External domain name API_ENDPOINT : FQDN for blockindex API FE_ENDPOINT : FQDN for frontend STATIC_DIR : The host machine directory that contains static files. Example for .env file: COINMARKETCAP_API_KEY=\"YOUR_KEY_HERE\" PYTHONPATH=. ETH_WS_URL=\"ws://localhost:8454\" # PostgreSQL settings POSTGRES_HOST=host.docker.internal POSTGRES_PORT=5432 POSTGRES_DB=blockindex POSTGRES_USER=blockindex POSTGRES_PASSWORD=blockindex CELERY_BROKER_URL=redis://redis:6379/0 CELERY_RESULT_BACKEND=redis://redis:6379/0 # Traefik EXT_ENDPOINT=blockindex.example API_ENDPOINT=demo-api.blockindex.dev FE_ENDPOINT=demo.blockindex.dev #nginx STATIC_DIR=/root/frontend Finally, execute the following command in root directory: docker compose -f prod.yml up -d Then the service could be visit via the following URL: BlockIndex API: http://api.localhost , http://api.${EXT_ENDPOINT} , http://${API_ENDPOINT} Static Files: http://nginx.localhost , http://nginx.${EXT_ENDPOINT} , http://${FE_ENDPOINT} Traefik Dashboard: http://traefik.localhost , http://traefik.${END_POINT}","title":"Deploy Setup"},{"location":"developers/","text":"Developers How to add a new EVM compatible blockchain Add a new EVM compatible blockchain is quite easy. Add a new ChainType enum in app/models/transaction.py . Define config name for chain provider in Settings class in app/core/config.py . Modify EVMClient.__init__ in app/core/evm.py for new chain provider. Then, you can add some indexer for testing new chain provider. If everything is set correctly, you can see the transaction for new chain provider in http://localhost:8000/api/v1/{chains}/transactions . How to create a new EventIndexer We take ERC20 as an example. 1. Add model: Add erc20_trans.py under app/model/ from .event_indexer import EventIndexer class ERC20Trans(EventIndexer): # 1. The model should inherit EventIndexer # 2. Should always add these 2 lines below, # so BlockIndex can auto index the relationship with transactions __mapper_args__ = dict(polymorphic_identity=\"erc20trans\") id = Column(Integer, ForeignKey(EventIndexer.id), primary_key=True) # 3. Add your other fields in the following... from_addr = Column(String, index=True) to_addr = Column(String, index=True) ... And do migration by running - make makemigrations MESSAGE=\"message about the new indexer\" - make migrate 2. Add schema: Add erc20_trans.py under app/schemas/ from .event_indexer import EventIndexerBase class ERC20TransBase(EventIndexerBase): # The model should inherit EventIndexerBase from_addr: Optional[str] = None to_addr: Optional[str] = None 3. Add crud and endpoint. The crud and endpoint parts require no special work. You can handle it in the same way that you would a regular table. 4. Add indexer Add erc20_trans_indexer.py under app/indexer/ from app.indexer import EventIndexerBasic class ERC20TransIndexer(EventIndexerBasic): abi = [...] # you need to add the abi def _index_event(db: Session, event: Dict[str, Any], block: Dict[str, Any]): # You must also implement how to save event data into the model here. And return the model obj. !! Please add ERC20TransIndexer inside app/indexer/__init__.py as follows, or it cannot be found via BasicIndexer. subclasses () from .erc20_trans_indexer import ERC20TransIndexer Then, when you run the rpc listener, your newly created model should be automatically indexed/updated. More information can be found in these files mentioned above. How to create a new Alert Here we try to build a erc20 transaction alert as an example. 1. Add ERC20TransAlertParams under app/schemas/alert_task_params ... class ERC20TransAlertParams(BaseModel): symbols: List[str] = [] value_threshold: Optional[int] = 0 ... Add newly created alert module inside app/alert/__init__.py from .erc20_trans_alert import ERC20TransAlert Add erc20_trans_alert.py under app/alert/ , and implement abi, params_schema, and check function Usually, you return the params defined under app/schemas/alert_task_params in the params_schema function. ```python class ERC20TransAlert(EventAlertBase): abi = ERC20_ABI @property def params_schema(self) -> Type[ERC20TransAlertParams]: return ERC20TransAlertParams def check(self, index_addr: IndexAddr, event: EventData, params: ERC20TransAlertParams) -> bool: # Define the situation under which the alert will be sent. # Return True if the requirement is met. ... ``` Update AlertClsName under app/models/alert_task class AlertClsName(str, enum.Enum): ERC20TransAlert = \"ERC20TransAlert\" ERC721TransAlert = \"ERC721TransAlert\" ...","title":"Developers"},{"location":"developers/#developers","text":"","title":"Developers"},{"location":"developers/#how-to-add-a-new-evm-compatible-blockchain","text":"Add a new EVM compatible blockchain is quite easy. Add a new ChainType enum in app/models/transaction.py . Define config name for chain provider in Settings class in app/core/config.py . Modify EVMClient.__init__ in app/core/evm.py for new chain provider. Then, you can add some indexer for testing new chain provider. If everything is set correctly, you can see the transaction for new chain provider in http://localhost:8000/api/v1/{chains}/transactions .","title":"How to add a new EVM compatible blockchain"},{"location":"developers/#how-to-create-a-new-eventindexer","text":"We take ERC20 as an example.","title":"How to create a new EventIndexer"},{"location":"developers/#1-add-model","text":"Add erc20_trans.py under app/model/ from .event_indexer import EventIndexer class ERC20Trans(EventIndexer): # 1. The model should inherit EventIndexer # 2. Should always add these 2 lines below, # so BlockIndex can auto index the relationship with transactions __mapper_args__ = dict(polymorphic_identity=\"erc20trans\") id = Column(Integer, ForeignKey(EventIndexer.id), primary_key=True) # 3. Add your other fields in the following... from_addr = Column(String, index=True) to_addr = Column(String, index=True) ... And do migration by running - make makemigrations MESSAGE=\"message about the new indexer\" - make migrate","title":"1. Add model:"},{"location":"developers/#2-add-schema","text":"Add erc20_trans.py under app/schemas/ from .event_indexer import EventIndexerBase class ERC20TransBase(EventIndexerBase): # The model should inherit EventIndexerBase from_addr: Optional[str] = None to_addr: Optional[str] = None","title":"2. Add schema:"},{"location":"developers/#3-add-crud-and-endpoint","text":"The crud and endpoint parts require no special work. You can handle it in the same way that you would a regular table.","title":"3. Add crud and endpoint."},{"location":"developers/#4-add-indexer","text":"Add erc20_trans_indexer.py under app/indexer/ from app.indexer import EventIndexerBasic class ERC20TransIndexer(EventIndexerBasic): abi = [...] # you need to add the abi def _index_event(db: Session, event: Dict[str, Any], block: Dict[str, Any]): # You must also implement how to save event data into the model here. And return the model obj. !! Please add ERC20TransIndexer inside app/indexer/__init__.py as follows, or it cannot be found via BasicIndexer. subclasses () from .erc20_trans_indexer import ERC20TransIndexer Then, when you run the rpc listener, your newly created model should be automatically indexed/updated. More information can be found in these files mentioned above.","title":"4. Add indexer"},{"location":"developers/#how-to-create-a-new-alert","text":"Here we try to build a erc20 transaction alert as an example. 1. Add ERC20TransAlertParams under app/schemas/alert_task_params ... class ERC20TransAlertParams(BaseModel): symbols: List[str] = [] value_threshold: Optional[int] = 0 ... Add newly created alert module inside app/alert/__init__.py from .erc20_trans_alert import ERC20TransAlert Add erc20_trans_alert.py under app/alert/ , and implement abi, params_schema, and check function Usually, you return the params defined under app/schemas/alert_task_params in the params_schema function. ```python class ERC20TransAlert(EventAlertBase): abi = ERC20_ABI @property def params_schema(self) -> Type[ERC20TransAlertParams]: return ERC20TransAlertParams def check(self, index_addr: IndexAddr, event: EventData, params: ERC20TransAlertParams) -> bool: # Define the situation under which the alert will be sent. # Return True if the requirement is met. ... ``` Update AlertClsName under app/models/alert_task class AlertClsName(str, enum.Enum): ERC20TransAlert = \"ERC20TransAlert\" ERC721TransAlert = \"ERC721TransAlert\" ...","title":"How to create a new Alert"},{"location":"installation/","text":"Installation Setup Pre-requirement Python 3.9 or Python 3.10. We recommend to use pyenv for your Python version management. poetry for package management Setup environment Install Python 3.9 using pyenv pyenv install 3.9.11 Install requirements from poetry poetry env use 3.9 poetry install Initial Database Database store in /tmp/test.db poetry run ./prestart.sh Add/Remove Model PYTHONPATH=. poetry run alembic revision --autogenerate -m Run local dev server poetry run ./run.sh Then you can visit http://localhost:8000/api/v1/items/ for items API. http://localhost:8000/docs for documentation Run RPC listener add ether chain websocket url inside .env ETH_WS_URL=\"<your ETH json-RPC websocket URL>\" Run PYTHONPATH=. poetry run python app/rpc_listener.py Run celery worker Redis is used for default broker and result backend. For local development, you could install redis via homebrew. poetry run ./worker-start.sh For periodic task, we should run celery beat worker. poetry run ./beat-worker-start.sh Use docker compose for local development Copy .env.example to .env Fill out ETH_WS_URL with a valid node wws url Change STATIC_DIR to / Change MODE to dev Build image make compose_build Run Development make compose_build","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#setup","text":"","title":"Setup"},{"location":"installation/#pre-requirement","text":"Python 3.9 or Python 3.10. We recommend to use pyenv for your Python version management. poetry for package management","title":"Pre-requirement"},{"location":"installation/#setup-environment","text":"Install Python 3.9 using pyenv pyenv install 3.9.11 Install requirements from poetry poetry env use 3.9 poetry install","title":"Setup environment"},{"location":"installation/#initial-database","text":"Database store in /tmp/test.db poetry run ./prestart.sh","title":"Initial Database"},{"location":"installation/#addremove-model","text":"PYTHONPATH=. poetry run alembic revision --autogenerate -m","title":"Add/Remove Model"},{"location":"installation/#run-local-dev-server","text":"poetry run ./run.sh Then you can visit http://localhost:8000/api/v1/items/ for items API. http://localhost:8000/docs for documentation","title":"Run local dev server"},{"location":"installation/#run-rpc-listener","text":"add ether chain websocket url inside .env ETH_WS_URL=\"<your ETH json-RPC websocket URL>\" Run PYTHONPATH=. poetry run python app/rpc_listener.py","title":"Run RPC listener"},{"location":"installation/#run-celery-worker","text":"Redis is used for default broker and result backend. For local development, you could install redis via homebrew. poetry run ./worker-start.sh For periodic task, we should run celery beat worker. poetry run ./beat-worker-start.sh","title":"Run celery worker"},{"location":"installation/#use-docker-compose-for-local-development","text":"Copy .env.example to .env Fill out ETH_WS_URL with a valid node wws url Change STATIC_DIR to / Change MODE to dev","title":"Use docker compose for local development"},{"location":"installation/#build-image","text":"make compose_build","title":"Build image"},{"location":"installation/#run-development","text":"make compose_build","title":"Run Development"}]}